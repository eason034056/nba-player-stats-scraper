#!/usr/bin/env python3
"""
NBA Player Game Logs Scraper
============================
é€™å€‹è…³æœ¬æœƒå¾ RealGM ç¶²ç«™çˆ¬å– NBA çƒå“¡çš„æ¯”è³½è¨˜éŒ„ï¼Œä¸¦å„²å­˜ç‚º CSV æª”æ¡ˆã€‚
å°ˆé–€è¨­è¨ˆç”¨æ–¼ GitHub Actions Cron Job è‡ªå‹•åŸ·è¡Œã€‚

åŠŸèƒ½èªªæ˜ï¼š
- è‡ªå‹•çˆ¬å–æ‰€æœ‰ NBA çƒå“¡çš„ Game Log è³‡æ–™
- é¸æ“‡æŒ‡å®šè³½å­£ï¼ˆç›®å‰æ˜¯ 2025-2026ï¼‰
- å„²å­˜ç‚º CSV æ ¼å¼
- å®Œæ•´çš„æ—¥èªŒè¨˜éŒ„å’ŒéŒ¯èª¤è™•ç†
"""

# ============================================================
# æ­¥é©Ÿ 1: åŒ¯å…¥æ‰€éœ€çš„å¥—ä»¶
# ============================================================

# selenium ç”¨æ–¼è‡ªå‹•åŒ–ç¶²é ç€è¦½å™¨æ“ä½œ
from selenium import webdriver
# By ç”¨æ–¼å®šä½ç¶²é å…ƒç´ çš„æ–¹å¼ï¼ˆå¦‚ CSS_SELECTOR, TAG_NAME ç­‰ï¼‰
from selenium.webdriver.common.by import By
# WebDriverWait ç”¨æ–¼ç­‰å¾…ç‰¹å®šæ¢ä»¶é”æˆï¼ˆé¡¯å¼ç­‰å¾…ï¼‰
from selenium.webdriver.support.ui import WebDriverWait
# expected_conditions (EC) æä¾›å¸¸ç”¨çš„ç­‰å¾…æ¢ä»¶
from selenium.webdriver.support import expected_conditions as EC
# Select ç”¨æ–¼æ“ä½œä¸‹æ‹‰é¸å–®ï¼ˆ<select> å…ƒç´ ï¼‰
from selenium.webdriver.support.ui import Select
# Service ç”¨æ–¼è¨­å®š ChromeDriver çš„æœå‹™
from selenium.webdriver.chrome.service import Service
# webdriver_manager è‡ªå‹•ä¸‹è¼‰å’Œç®¡ç† ChromeDriver ç‰ˆæœ¬
# é€™æ¨£å°±ä¸éœ€è¦æ‰‹å‹•ä¸‹è¼‰ ChromeDriverï¼Œæœƒè‡ªå‹•é…å° Chrome ç‰ˆæœ¬
from webdriver_manager.chrome import ChromeDriverManager

# pandas ç”¨æ–¼è³‡æ–™è™•ç†å’Œå„²å­˜æˆ CSV æ ¼å¼
import pandas as pd
# time ç”¨æ–¼æ§åˆ¶ç¨‹å¼åŸ·è¡Œé€Ÿåº¦ï¼ˆé¿å…å°ä¼ºæœå™¨é€ æˆè² æ“”ï¼‰
import time
# logging ç”¨æ–¼è¨˜éŒ„ç¨‹å¼åŸ·è¡Œéç¨‹ï¼ˆæ¯” print æ›´å°ˆæ¥­ï¼‰
import logging
# os ç”¨æ–¼è™•ç†æª”æ¡ˆè·¯å¾‘å’Œç’°å¢ƒè®Šæ•¸
import os
# sys ç”¨æ–¼ç¨‹å¼é€€å‡ºå’Œç³»çµ±ç›¸é—œæ“ä½œ
import sys
# datetime ç”¨æ–¼è™•ç†æ—¥æœŸæ™‚é–“
from datetime import datetime

# ============================================================
# æ­¥é©Ÿ 2: è¨­å®šæ—¥èªŒç³»çµ±
# ============================================================
# logging.basicConfig() è¨­å®šæ—¥èªŒçš„åŸºæœ¬é…ç½®
# format: æ—¥èªŒæ ¼å¼ï¼ŒåŒ…å«æ™‚é–“ã€ç­‰ç´šã€è¨Šæ¯
# level: æ—¥èªŒç­‰ç´šï¼ŒINFO è¡¨ç¤ºè¨˜éŒ„ä¸€èˆ¬è³‡è¨Šä»¥ä¸Šçš„è¨Šæ¯
# handlers: æ—¥èªŒè™•ç†å™¨ï¼ŒåŒæ™‚è¼¸å‡ºåˆ°æª”æ¡ˆå’Œçµ‚ç«¯æ©Ÿ
logging.basicConfig(
    format='%(asctime)s - %(levelname)s - %(message)s',  # æ ¼å¼ï¼šæ™‚é–“ - ç­‰ç´š - è¨Šæ¯
    level=logging.INFO,  # ç­‰ç´šï¼šINFOï¼ˆä¸€èˆ¬è³‡è¨Šï¼‰
    handlers=[
        logging.StreamHandler(sys.stdout),  # StreamHandler è¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿï¼ˆstdoutï¼‰
        logging.FileHandler('scrape_log.txt', encoding='utf-8')  # FileHandler è¼¸å‡ºåˆ°æª”æ¡ˆ
    ]
)
logger = logging.getLogger(__name__)

# ============================================================
# æ­¥é©Ÿ 3: CSV æª”æ¡ˆè¨­å®š
# ============================================================
CSV_FILENAME = "nba_player_game_logs.csv"
SEASON = "2025-2026"

# CSV æ¬„ä½åç¨±ï¼ˆç”¨æ–¼å»ºç«‹ DataFrameï¼‰
COLUMNS = [
    "Player", "Season", "Date", "Team", "Opponent", "W/L", "Status",
    "Pos", "MIN", "PTS", "FGM", "FGA", "FG%", "3PM", "3PA", "3P%",
    "FTM", "FTA", "FT%", "ORB", "DRB", "REB", "AST", "STL", "BLK",
    "TOV", "PF", "FIC"
]


def load_existing_data():
    """
    è¼‰å…¥ç¾æœ‰çš„ CSV è³‡æ–™
    
    Returns:
        tuple: (df, player_last_dates)
        - df: pandas DataFrameï¼Œç¾æœ‰è³‡æ–™ï¼ˆå¦‚æœæ²’æœ‰æª”æ¡ˆå‰‡ç‚ºç©º DataFrameï¼‰
        - player_last_dates: dictï¼Œæ¯ä½çƒå“¡æœ€å¾Œä¸€å ´æ¯”è³½çš„æ—¥æœŸ
          æ ¼å¼ï¼š{"LeBron James": datetime(2025, 1, 28), ...}
    
    é€™å€‹å‡½æ•¸æœƒï¼š
    1. å˜—è©¦è®€å–ç¾æœ‰çš„ CSV æª”æ¡ˆ
    2. è§£ææ¯ä½çƒå“¡æœ€æ–°çš„æ¯”è³½æ—¥æœŸ
    3. è¿”å›è³‡æ–™ä¾›å¾ŒçºŒå¢é‡çˆ¬å–ä½¿ç”¨
    """
    player_last_dates = {}
    
    # os.path.exists() æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if os.path.exists(CSV_FILENAME):
        try:
            # pd.read_csv() è®€å– CSV æª”æ¡ˆ
            df = pd.read_csv(CSV_FILENAME, encoding='utf-8-sig')
            logger.info(f"å·²è¼‰å…¥ç¾æœ‰è³‡æ–™ï¼š{len(df)} ç­†è¨˜éŒ„")
            
            # è§£ææ¯ä½çƒå“¡çš„æœ€æ–°æ¯”è³½æ—¥æœŸ
            # groupby('Player') æŒ‰çƒå“¡åˆ†çµ„
            for player, group in df.groupby('Player'):
                # å–å¾—è©²çƒå“¡æ‰€æœ‰æ¯”è³½æ—¥æœŸ
                dates = group['Date'].tolist()
                
                # å˜—è©¦è§£ææ—¥æœŸï¼Œæ‰¾å‡ºæœ€æ–°çš„
                latest_date = None
                for date_str in dates:
                    try:
                        # pd.to_datetime() å°‡å­—ä¸²è½‰æ›ç‚ºæ—¥æœŸ
                        # format='%m/%d/%Y' æŒ‡å®šæ—¥æœŸæ ¼å¼ï¼ˆå¦‚ "1/25/2026"ï¼‰
                        parsed_date = pd.to_datetime(date_str, format='%m/%d/%Y')
                        if latest_date is None or parsed_date > latest_date:
                            latest_date = parsed_date
                    except Exception:
                        continue
                
                if latest_date:
                    # å„²å­˜æ¯ä½çƒå“¡çš„æœ€æ–°æ¯”è³½æ—¥æœŸ
                    player_last_dates[player] = latest_date
            
            logger.info(f"æ‰¾åˆ° {len(player_last_dates)} ä½çƒå“¡çš„æ­·å²è³‡æ–™")
            return df, player_last_dates
            
        except Exception as e:
            logger.warning(f"ç„¡æ³•è®€å–ç¾æœ‰ CSV æª”æ¡ˆï¼š{e}")
            # è¿”å›ç©ºçš„ DataFrame
            return pd.DataFrame(columns=COLUMNS), {}
    else:
        logger.info("æ²’æœ‰æ‰¾åˆ°ç¾æœ‰çš„ CSV æª”æ¡ˆï¼Œå°‡é€²è¡Œå®Œæ•´çˆ¬å–")
        return pd.DataFrame(columns=COLUMNS), {}


def setup_chrome_driver():
    """
    è¨­å®šä¸¦å•Ÿå‹• Chrome ç€è¦½å™¨ï¼ˆHeadless æ¨¡å¼ï¼‰
    
    Returns:
        tuple: (driver, wait) - WebDriver ç‰©ä»¶å’Œ WebDriverWait ç‰©ä»¶
        
    é€™å€‹å‡½æ•¸åšäº†ä»¥ä¸‹äº‹æƒ…ï¼š
    1. è¨­å®š Chrome çš„å„ç¨®é¸é …ï¼ˆheadlessã€ååµæ¸¬ç­‰ï¼‰
    2. ä½¿ç”¨ webdriver_manager è‡ªå‹•ç®¡ç† ChromeDriver
    3. è¿”å›å¯ç”¨çš„ driver å’Œ wait ç‰©ä»¶
    """
    logger.info("æ­£åœ¨è¨­å®š Chrome ç€è¦½å™¨...")
    
    # webdriver.ChromeOptions() å‰µå»ºä¸€å€‹ Chrome ç€è¦½å™¨çš„é…ç½®å°è±¡
    options = webdriver.ChromeOptions()
    
    # ============================================================
    # ã€é‡è¦ã€‘Headless æ¨¡å¼è¨­å®š - GitHub Actions å¿…é ˆå•Ÿç”¨
    # ============================================================
    # add_argument("--headless") è®“ç€è¦½å™¨åœ¨èƒŒæ™¯åŸ·è¡Œï¼Œä¸æœƒé–‹å•Ÿè¦–çª—
    # é€™å°æ–¼ä¼ºæœå™¨ç’°å¢ƒï¼ˆå¦‚ GitHub Actionsï¼‰æ˜¯å¿…è¦çš„ï¼Œå› ç‚ºæ²’æœ‰ GUI
    options.add_argument("--headless")
    
    # add_argument("--no-sandbox") é—œé–‰æ²™ç›’æ¨¡å¼
    # åœ¨ Docker æˆ– CI/CD ç’°å¢ƒä¸­ï¼Œæ²™ç›’æ¨¡å¼å¯èƒ½æœƒé€ æˆæ¬Šé™å•é¡Œ
    # æ²™ç›’æ˜¯ä¸€ç¨®å®‰å…¨æ©Ÿåˆ¶ï¼Œé™åˆ¶ç€è¦½å™¨å°ç³»çµ±çš„å­˜å–
    options.add_argument("--no-sandbox")
    
    # add_argument("--disable-dev-shm-usage") è§£æ±ºè³‡æºé™åˆ¶å•é¡Œ
    # /dev/shm æ˜¯ Linux çš„å…±äº«è¨˜æ†¶é«”ï¼Œé è¨­åªæœ‰ 64MB
    # é€™å€‹é¸é …è®“ Chrome ä½¿ç”¨ /tmp è€Œä¸æ˜¯ /dev/shm
    options.add_argument("--disable-dev-shm-usage")
    
    # add_argument("--disable-gpu") ç¦ç”¨ GPU åŠ é€Ÿ
    # åœ¨ headless æ¨¡å¼å’Œä¼ºæœå™¨ç’°å¢ƒä¸­ï¼ŒGPU é€šå¸¸ä¸å¯ç”¨
    options.add_argument("--disable-gpu")
    
    # add_argument("--remote-debugging-port=9222") è¨­å®šé ç«¯é™¤éŒ¯ç«¯å£
    # é€™å¯ä»¥å¹«åŠ©è§£æ±ºæŸäº› headless æ¨¡å¼çš„å•é¡Œ
    options.add_argument("--remote-debugging-port=9222")
    
    # ============================================================
    # ååµæ¸¬è¨­å®š - è®“ç€è¦½å™¨çœ‹èµ·ä¾†åƒçœŸäººæ“ä½œ
    # ============================================================
    
    # è¨­å®šè¦–çª—å¤§å°ï¼Œæ¨¡æ“¬çœŸå¯¦ç€è¦½å™¨çš„è§£æåº¦
    # å¦‚æœä¸è¨­å®šï¼Œheadless æ¨¡å¼çš„è¦–çª—å¯èƒ½æ˜¯ 800x600ï¼ˆçœ‹èµ·ä¾†å¾ˆå¯ç–‘ï¼‰
    options.add_argument("--window-size=1920,1080")
    
    # è¨­å®š User-Agentï¼Œè®“ç¶²ç«™èªç‚ºé€™æ˜¯æ­£å¸¸çš„ Chrome ç€è¦½å™¨
    # User-Agent æ˜¯ç€è¦½å™¨å‘ä¼ºæœå™¨ç™¼é€çš„èº«ä»½è­˜åˆ¥å­—ä¸²
    # é è¨­çš„ headless User-Agent æœƒåŒ…å« "HeadlessChrome" å­—æ¨£
    options.add_argument(
        "user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )
    
    # ç¦ç”¨ Blink å¼•æ“çš„è‡ªå‹•åŒ–æ§åˆ¶ç‰¹å¾µ
    # Blink æ˜¯ Chrome çš„æ¸²æŸ“å¼•æ“
    # AutomationControlled æ˜¯ä¸€å€‹æœƒæš´éœ² Selenium çš„ç‰¹å¾µ
    options.add_argument("--disable-blink-features=AutomationControlled")
    
    # excludeSwitches æ’é™¤æŸäº› Chrome å•Ÿå‹•åƒæ•¸
    # "enable-automation" æœƒåœ¨è¦–çª—é¡¯ç¤ºã€ŒChrome æ­£ç”±è‡ªå‹•åŒ–æ¸¬è©¦è»Ÿé«”æ§åˆ¶ã€
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    
    # useAutomationExtension ç¦ç”¨è‡ªå‹•åŒ–æ“´å±•
    # é€™å€‹æ“´å±•æ˜¯ Selenium ç”¨ä¾†æ§åˆ¶ç€è¦½å™¨çš„ï¼Œä½†æœƒè¢«æŸäº›ç¶²ç«™åµæ¸¬
    options.add_experimental_option('useAutomationExtension', False)
    
    # ============================================================
    # å•Ÿå‹• Chrome ç€è¦½å™¨
    # ============================================================
    # ChromeDriverManager().install() è‡ªå‹•ä¸‹è¼‰é©åˆçš„ ChromeDriver
    # é€™æ¯”æ‰‹å‹•ä¸‹è¼‰æ›´æ–¹ä¾¿ï¼Œä¸”æœƒè‡ªå‹•åŒ¹é… Chrome ç‰ˆæœ¬
    # Service() ç”¨æ–¼è¨­å®š ChromeDriver çš„æœå‹™
    service = Service(ChromeDriverManager().install())
    
    # webdriver.Chrome() ä½¿ç”¨ä¸Šè¿°é…ç½®å•Ÿå‹• Chrome ç€è¦½å™¨
    driver = webdriver.Chrome(service=service, options=options)
    
    # execute_cdp_cmd() åŸ·è¡Œ Chrome DevTools Protocol å‘½ä»¤
    # é€™è£¡ç”¨ä¾†ä¿®æ”¹ navigator.webdriver å±¬æ€§
    # æ­£å¸¸æƒ…æ³ä¸‹ï¼ŒSelenium æœƒè¨­å®š navigator.webdriver = true
    # é€™æ®µ JavaScript å°‡å®ƒæ”¹ç‚º undefinedï¼Œå°±åƒçœŸå¯¦ç€è¦½å™¨ä¸€æ¨£
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': '''
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            })
        '''
    })
    
    # WebDriverWait(driver, 45) å‰µå»ºä¸€å€‹ç­‰å¾…ç‰©ä»¶
    # 45 æ˜¯æœ€é•·ç­‰å¾…ç§’æ•¸
    # ç•¶éœ€è¦ç­‰å¾…ç¶²é å…ƒç´ è¼‰å…¥æ™‚ä½¿ç”¨
    wait = WebDriverWait(driver, 45)
    
    logger.info("Chrome ç€è¦½å™¨å·²å•Ÿå‹•ï¼ˆHeadless æ¨¡å¼ + ååµæ¸¬é…ç½®ï¼‰")
    return driver, wait


def get_player_links(driver, wait):
    """
    å–å¾—æ‰€æœ‰ NBA çƒå“¡çš„é€£çµ
    
    Args:
        driver: Selenium WebDriver ç‰©ä»¶
        wait: WebDriverWait ç‰©ä»¶
        
    Returns:
        list: æ‰€æœ‰çƒå“¡é é¢çš„ URL åˆ—è¡¨
        
    é€™å€‹å‡½æ•¸åšäº†ä»¥ä¸‹äº‹æƒ…ï¼š
    1. è¨ªå• RealGM çš„çƒå“¡åˆ—è¡¨é é¢
    2. ç­‰å¾…é é¢è¼‰å…¥å®Œæˆ
    3. æå–æ‰€æœ‰çƒå“¡çš„é€£çµ
    """
    logger.info("æ­£åœ¨è¼‰å…¥çƒå“¡åˆ—è¡¨é é¢...")
    
    # driver.get() è®“ç€è¦½å™¨è¨ªå•æŒ‡å®šçš„ç¶²å€
    driver.get("https://basketball.realgm.com/nba/players")
    
    # wait.until() ç­‰å¾…ç›´åˆ°æŒ‡å®šæ¢ä»¶é”æˆ
    # EC.presence_of_element_located() æª¢æŸ¥å…ƒç´ æ˜¯å¦å‡ºç¾åœ¨ DOM ä¸­
    # (By.CSS_SELECTOR, "table") ä½¿ç”¨ CSS é¸æ“‡å™¨å°‹æ‰¾ <table> å…ƒç´ 
    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table")))
    
    # å–å¾—çƒå“¡é€£çµå’Œå§“å
    player_elements = driver.find_elements(By.CSS_SELECTOR, "table tbody tr td:nth-child(2) a")
    
    # åŒæ™‚å–å¾—çƒå“¡å§“åå’Œé€£çµ
    # é€™æ¨£å¯ä»¥åœ¨ä¹‹å¾Œå¿«é€Ÿåˆ¤æ–·æ˜¯å¦éœ€è¦çˆ¬å–
    players = []
    for elem in player_elements:
        name = elem.text.strip()
        url = elem.get_attribute("href")
        players.append((name, url))
    
    logger.info(f"æ‰¾åˆ° {len(players)} ä½çƒå“¡")
    return players


def should_scrape_player(player_name, player_last_dates):
    """
    åˆ¤æ–·æ˜¯å¦éœ€è¦çˆ¬å–è©²çƒå“¡çš„è³‡æ–™
    
    Args:
        player_name: strï¼Œçƒå“¡å§“å
        player_last_dates: dictï¼Œæ¯ä½çƒå“¡æœ€å¾Œä¸€å ´æ¯”è³½çš„æ—¥æœŸ
        
    Returns:
        tuple: (should_scrape, reason)
        - should_scrape: boolï¼Œæ˜¯å¦éœ€è¦çˆ¬å–
        - reason: strï¼ŒåŸå› èªªæ˜
    
    åˆ¤æ–·é‚è¼¯ï¼š
    1. å¦‚æœæ˜¯æ–°çƒå“¡ï¼ˆæ²’æœ‰æ­·å²è³‡æ–™ï¼‰â†’ éœ€è¦å®Œæ•´çˆ¬å–
    2. å¦‚æœæœ€å¾Œä¸€å ´æ¯”è³½æ˜¯ä»Šå¤©æˆ–æ˜¨å¤© â†’ å¯èƒ½ä¸éœ€è¦çˆ¬å–
    3. å¦‚æœæœ€å¾Œä¸€å ´æ¯”è³½è¶…é 1 å¤© â†’ éœ€è¦çˆ¬å–æ–°è³‡æ–™
    """
    today = datetime.now()
    
    # å¦‚æœæ˜¯æ–°çƒå“¡ï¼Œéœ€è¦å®Œæ•´çˆ¬å–
    if player_name not in player_last_dates:
        return True, "æ–°çƒå“¡"
    
    last_date = player_last_dates[player_name]
    days_since_last = (today - last_date).days
    
    # å¦‚æœæœ€å¾Œä¸€å ´æ¯”è³½æ˜¯ä»Šå¤© â†’ ä¸éœ€è¦çˆ¬å–
    if days_since_last == 0:
        return False, "ä»Šå¤©å·²æœ‰è³‡æ–™"
    
    # å¦‚æœè¶…é 1 å¤©æ²’æœ‰æ–°è³‡æ–™ â†’ éœ€è¦çˆ¬å–
    # ï¼ˆå› ç‚º NBA æ¯”è³½é€šå¸¸æ¯ 1-2 å¤©å°±æœ‰ï¼‰
    return True, f"è·ä¸Šæ¬¡ {days_since_last} å¤©"


def get_player_name_from_page(driver):
    """å¾é é¢å–å¾—çƒå“¡å§“å"""
    try:
        h2_element = driver.find_element(By.CSS_SELECTOR, "div.half-column-left h2")
        player_name_raw = driver.execute_script("""
            var h2 = arguments[0];
            var text = '';
            for (var i = 0; i < h2.childNodes.length; i++) {
                if (h2.childNodes[i].nodeType === Node.TEXT_NODE) {
                    text += h2.childNodes[i].nodeValue;
                }
            }
            return text.trim();
        """, h2_element)
        return player_name_raw.strip()
    except Exception:
        return None


def select_dropdown_option(select_element, options_to_try, fallback_index=0):
    """å˜—è©¦é¸æ“‡ä¸‹æ‹‰é¸å–®çš„é¸é …"""
    for option_text in options_to_try:
        try:
            select_element.select_by_visible_text(option_text)
            return True
        except Exception:
            continue
    try:
        select_element.select_by_index(fallback_index)
        return True
    except Exception:
        return False


def parse_game_date(date_str):
    """
    è§£ææ¯”è³½æ—¥æœŸå­—ä¸²
    
    Args:
        date_str: strï¼Œæ—¥æœŸå­—ä¸²ï¼ˆå¦‚ "1/25/2026"ï¼‰
        
    Returns:
        datetime æˆ– None
    """
    try:
        return pd.to_datetime(date_str, format='%m/%d/%Y')
    except Exception:
        return None


def scrape_player_games(driver, wait, player_name, game_log_url, last_date=None):
    """
    çˆ¬å–å–®ä¸€çƒå“¡çš„æ¯”è³½è³‡æ–™
    
    Args:
        driver: Selenium WebDriver
        wait: WebDriverWait
        player_name: strï¼Œçƒå“¡å§“å
        game_log_url: strï¼ŒGame Log é é¢ URL
        last_date: datetime æˆ– Noneï¼Œè©²çƒå“¡æœ€å¾Œä¸€å ´æ¯”è³½çš„æ—¥æœŸ
                   å¦‚æœæä¾›ï¼Œåªæœƒçˆ¬å–æ¯”é€™å€‹æ—¥æœŸæ›´æ–°çš„æ¯”è³½
    
    Returns:
        list: æ–°çš„æ¯”è³½è¨˜éŒ„åˆ—è¡¨
    
    ã€å¢é‡çˆ¬å–çš„æ ¸å¿ƒé‚è¼¯ã€‘
    ç•¶ last_date ä¸ç‚º None æ™‚ï¼Œåªçˆ¬å–æ—¥æœŸ > last_date çš„æ¯”è³½
    é€™æ¨£å¯ä»¥å¤§å¹…æ¸›å°‘éœ€è¦è™•ç†çš„è³‡æ–™é‡
    """
    new_games = []
    
    try:
        driver.get(game_log_url)
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table")))
        
        # å¾é é¢å–å¾—çƒå“¡å§“åï¼ˆæ›´æº–ç¢ºï¼‰
        page_player_name = get_player_name_from_page(driver)
        if page_player_name:
            player_name = page_player_name
        
        # è¨­å®šä¸‹æ‹‰é¸å–®
        selects = driver.find_elements(By.TAG_NAME, "select")
        
        if len(selects) >= 3:
            # League
            league_select = Select(selects[0])
            select_dropdown_option(league_select, ["NBA"])
            time.sleep(1)  # ã€å„ªåŒ–ã€‘æ¸›å°‘ç­‰å¾…æ™‚é–“
            
            # Season
            season_select = Select(selects[1])
            season_variations = [SEASON, SEASON.replace("-20", "-")]
            select_dropdown_option(season_select, season_variations)
            time.sleep(1)
            
            # Games
            games_select = Select(selects[2])
            select_dropdown_option(games_select, ["All Games", "Regular Season"])
            time.sleep(1.5)
            
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody")))
            time.sleep(0.5)
        
        # æŠ“å–è¡¨æ ¼è³‡æ–™
        rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
        
        for row_idx in range(len(rows)):
            try:
                rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
                if row_idx >= len(rows):
                    break
                
                row = rows[row_idx]
                cells = row.find_elements(By.TAG_NAME, "td")
                cell_data = [cell.text.strip() for cell in cells]
                
                if not cell_data or len(cell_data) < 3:
                    continue
                
                # ã€å¢é‡çˆ¬å–é—œéµã€‘æª¢æŸ¥æ—¥æœŸ
                # cell_data[0] æ˜¯æ—¥æœŸæ¬„ä½
                game_date = parse_game_date(cell_data[0])
                
                if last_date and game_date:
                    # å¦‚æœé€™å ´æ¯”è³½çš„æ—¥æœŸ <= æœ€å¾Œè¨˜éŒ„çš„æ—¥æœŸï¼Œè·³é
                    if game_date <= last_date:
                        continue
                
                # åŠ ä¸Šçƒå“¡å§“åå’Œè³½å­£
                cell_data_with_info = [player_name, SEASON] + cell_data
                new_games.append(cell_data_with_info)
                
            except Exception:
                continue
        
        return new_games
        
    except Exception as e:
        logger.warning(f"çˆ¬å– {player_name} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)[:100]}")
        return []


def scrape_all_players(driver, wait, players, player_last_dates):
    """
    çˆ¬å–æ‰€æœ‰çƒå“¡çš„æ¯”è³½è³‡æ–™ï¼ˆå¢é‡æ¨¡å¼ï¼‰
    
    Args:
        driver: Selenium WebDriver
        wait: WebDriverWait
        players: listï¼Œ(player_name, url) çš„ tuple åˆ—è¡¨
        player_last_dates: dictï¼Œæ¯ä½çƒå“¡æœ€å¾Œä¸€å ´æ¯”è³½çš„æ—¥æœŸ
        
    Returns:
        tuple: (all_new_games, stats)
        - all_new_games: listï¼Œæ‰€æœ‰æ–°çš„æ¯”è³½è¨˜éŒ„
        - stats: dictï¼Œçµ±è¨ˆè³‡è¨Š
    """
    all_new_games = []
    stats = {
        'total': len(players),
        'scraped': 0,        # æœ‰çˆ¬å–çš„çƒå“¡æ•¸
        'skipped': 0,        # è·³éçš„çƒå“¡æ•¸
        'new_games': 0,      # æ–°å¢çš„æ¯”è³½æ•¸
        'errors': 0          # éŒ¯èª¤æ•¸
    }
    
    for idx, (player_name, link) in enumerate(players, start=1):
        # åˆ¤æ–·æ˜¯å¦éœ€è¦çˆ¬å–
        should_scrape, reason = should_scrape_player(player_name, player_last_dates)
        
        if not should_scrape:
            # ã€å„ªåŒ–ã€‘è·³éä¸éœ€è¦çˆ¬å–çš„çƒå“¡
            if idx % 50 == 0:  # æ¯ 50 ä½çƒå“¡é¡¯ç¤ºä¸€æ¬¡é€²åº¦
                logger.info(f"é€²åº¦ï¼š{idx}/{len(players)} - å·²è·³éå¤šä½ç„¡éœ€æ›´æ–°çš„çƒå“¡")
            stats['skipped'] += 1
            continue
        
        # å–å¾—è©²çƒå“¡çš„æœ€å¾Œæ¯”è³½æ—¥æœŸï¼ˆå¦‚æœæœ‰ï¼‰
        last_date = player_last_dates.get(player_name)
        
        # å°‡ URL è½‰æ›ç‚º Game Log URL
        game_log_url = link.replace("/Summary/", "/GameLogs/")
        
        # é¡¯ç¤ºé€²åº¦
        logger.info(f"[{idx}/{len(players)}] {player_name} ({reason})")
        
        # é‡è©¦æ©Ÿåˆ¶
        max_retries = 2  # ã€å„ªåŒ–ã€‘æ¸›å°‘é‡è©¦æ¬¡æ•¸
        for retry in range(max_retries):
            try:
                new_games = scrape_player_games(
                    driver, wait, player_name, game_log_url, last_date
                )
                
                if new_games:
                    all_new_games.extend(new_games)
                    stats['new_games'] += len(new_games)
                    logger.info(f"  âœ“ æ–°å¢ {len(new_games)} å ´æ¯”è³½")
                else:
                    logger.info(f"  âœ“ ç„¡æ–°æ¯”è³½")
                
                stats['scraped'] += 1
                break
                
            except Exception as e:
                if retry < max_retries - 1:
                    time.sleep(2)
                else:
                    stats['errors'] += 1
                    logger.warning(f"  âœ— éŒ¯èª¤ï¼š{str(e)[:50]}")
        
        # ã€å„ªåŒ–ã€‘æ¸›å°‘ç­‰å¾…æ™‚é–“
        time.sleep(0.8)
    
    return all_new_games, stats


def save_data(existing_df, new_games):
    """
    åˆä½µä¸¦å„²å­˜è³‡æ–™
    
    Args:
        existing_df: pandas DataFrameï¼Œç¾æœ‰è³‡æ–™
        new_games: listï¼Œæ–°çš„æ¯”è³½è¨˜éŒ„
        
    Returns:
        pandas DataFrameï¼Œåˆä½µå¾Œçš„è³‡æ–™
    
    é€™å€‹å‡½æ•¸æœƒï¼š
    1. å°‡æ–°è³‡æ–™è½‰æ›ç‚º DataFrame
    2. èˆ‡ç¾æœ‰è³‡æ–™åˆä½µ
    3. ç§»é™¤é‡è¤‡è¨˜éŒ„
    4. æŒ‰çƒå“¡å’Œæ—¥æœŸæ’åº
    5. å„²å­˜ç‚º CSV
    """
    if not new_games:
        logger.info("æ²’æœ‰æ–°è³‡æ–™éœ€è¦å„²å­˜")
        return existing_df
    
    # å»ºç«‹æ–°è³‡æ–™çš„ DataFrame
    new_df = pd.DataFrame(new_games, columns=COLUMNS)
    logger.info(f"æ–°å¢ {len(new_df)} ç­†è¨˜éŒ„")
    
    # åˆä½µç¾æœ‰è³‡æ–™å’Œæ–°è³‡æ–™
    # pd.concat() å°‡å¤šå€‹ DataFrame åˆä½µ
    # ignore_index=True é‡æ–°ç·¨æ’ç´¢å¼•
    if not existing_df.empty:
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
    else:
        combined_df = new_df
    
    # ç§»é™¤é‡è¤‡è¨˜éŒ„
    # subset æŒ‡å®šç”¨æ–¼åˆ¤æ–·é‡è¤‡çš„æ¬„ä½
    # keep='last' ä¿ç•™æœ€å¾Œå‡ºç¾çš„è¨˜éŒ„ï¼ˆæ–°è³‡æ–™ï¼‰
    combined_df = combined_df.drop_duplicates(
        subset=['Player', 'Date', 'Team', 'Opponent'],
        keep='last'
    )
    
    # æŒ‰çƒå“¡å§“åå’Œæ—¥æœŸæ’åº
    # å…ˆå°‡æ—¥æœŸè½‰æ›ç‚º datetime æ ¼å¼ä»¥ä¾¿æ­£ç¢ºæ’åº
    combined_df['_date_sort'] = pd.to_datetime(
        combined_df['Date'], 
        format='%m/%d/%Y', 
        errors='coerce'
    )
    combined_df = combined_df.sort_values(
        ['Player', '_date_sort'], 
        ascending=[True, False]  # çƒå“¡å‡åºï¼Œæ—¥æœŸé™åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    )
    # ç§»é™¤æ’åºç”¨çš„è‡¨æ™‚æ¬„ä½
    combined_df = combined_df.drop('_date_sort', axis=1)
    
    # å„²å­˜ç‚º CSV
    combined_df.to_csv(CSV_FILENAME, index=False, encoding='utf-8-sig')
    logger.info(f"è³‡æ–™å·²å„²å­˜è‡³ {CSV_FILENAME}")
    logger.info(f"ç¸½å…± {len(combined_df)} ç­†è¨˜éŒ„")
    
    return combined_df


def main():
    """ä¸»ç¨‹å¼å…¥å£é»"""
    start_time = datetime.now()
    logger.info("=" * 60)
    logger.info(f"NBA Game Log çˆ¬èŸ²é–‹å§‹åŸ·è¡Œï¼ˆå¢é‡æ¨¡å¼ï¼‰")
    logger.info(f"é–‹å§‹æ™‚é–“ï¼š{start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)
    
    driver = None
    exit_code = 0
    
    try:
        # æ­¥é©Ÿ 1: è¼‰å…¥ç¾æœ‰è³‡æ–™
        existing_df, player_last_dates = load_existing_data()
        
        # æ­¥é©Ÿ 2: å•Ÿå‹•ç€è¦½å™¨
        driver, wait = setup_chrome_driver()
        
        # æ­¥é©Ÿ 3: å–å¾—çƒå“¡åˆ—è¡¨
        players = get_player_links(driver, wait)
        
        if not players:
            logger.error("æœªæ‰¾åˆ°ä»»ä½•çƒå“¡ï¼")
            return 1
        
        # æ­¥é©Ÿ 4: çˆ¬å–è³‡æ–™ï¼ˆå¢é‡æ¨¡å¼ï¼‰
        new_games, stats = scrape_all_players(driver, wait, players, player_last_dates)
        
        # æ­¥é©Ÿ 5: å„²å­˜è³‡æ–™
        save_data(existing_df, new_games)
        
        # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
        logger.info("=" * 60)
        logger.info("çˆ¬èŸ²çµ±è¨ˆè³‡è¨Šï¼š")
        logger.info("=" * 60)
        logger.info(f"ç¸½çƒå“¡æ•¸ï¼š{stats['total']}")
        logger.info(f"å·²çˆ¬å–ï¼š{stats['scraped']} ä½çƒå“¡")
        logger.info(f"å·²è·³éï¼š{stats['skipped']} ä½çƒå“¡ï¼ˆç„¡éœ€æ›´æ–°ï¼‰")
        logger.info(f"æ–°å¢æ¯”è³½ï¼š{stats['new_games']} å ´")
        logger.info(f"éŒ¯èª¤ï¼š{stats['errors']} æ¬¡")
        
        # è¨ˆç®—ç¯€çœçš„æ™‚é–“
        if stats['skipped'] > 0:
            saved_time = stats['skipped'] * 7  # æ¯ä½çƒå“¡ç´„ 7 ç§’
            logger.info(f"ğŸ“ˆ å¢é‡æ¨¡å¼ç¯€çœç´„ {saved_time // 60} åˆ†é˜")
        
    except Exception as e:
        logger.error(f"ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")
        exit_code = 1
        
    finally:
        if driver:
            driver.quit()
            logger.info("ç€è¦½å™¨å·²é—œé–‰")
        
        end_time = datetime.now()
        duration = end_time - start_time
        logger.info(f"åŸ·è¡Œæ™‚é–“ï¼š{duration}")
        logger.info("=" * 60)
    
    return exit_code


if __name__ == "__main__":
    sys.exit(main())
